{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collabrative Filtering (Low Rank Matrix Factorization)\n",
    "\n",
    "The goal is to fill in entries that are undefined. I use the following notations:\n",
    "- $x^{(i)}$ as latent variables for item $i$, where $x^{(i)}\\in \\mathbb{R}^n$, and $i\\in\\{1,\\cdots,n_i\\}$\n",
    "- $\\theta^{(j)}$ as corresponding parameters for user $j$, where $\\theta^{(j)}\\in \\mathbb{R}^n$, and $j\\in\\{1,\\cdots,n_u\\}$\n",
    "- $y^{(i,j)}$ as rating for item $i$ and user $j$\n",
    "\n",
    "Cost function with $L_2$ regularization is\n",
    "$$J(x^{(1)},\\cdots,x^{(n_i)},\\theta^{(1)},\\cdots,\\theta^{(n_u)})=\\frac{1}{2}\\sum_{(i,j):y^{(i,j)}\\in \\mathbb{R}} \\left(\\theta^{(j)\\top} x^{(i)}-y^{(i,j)}\\right)^2 + \\frac{\\lambda}{2} \\left(\\sum_{i=1}^{n_i}\\lVert x^{(i)} \\rVert^2 + \\sum_{j=1}^{n_u}\\lVert \\theta^{(j)} \\rVert^2 \\right) $$\n",
    "\n",
    "I stack $x^{(i)}$ by rows (i.e. $X\\in \\mathbb{R}^{n_i \\times n}$), $\\theta^{(j)}$ by rows (i.e. $\\Theta\\in \\mathbb{R}^{n_u \\times n}$) for vectorized computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(X, Theta, Y, has_rating, reg):\n",
    "    error = (X @ Theta.T - Y) * has_rating\n",
    "    squared_diff = np.sum(error @ error.T) / 2\n",
    "    penalty = reg / 2 * (np.linalg.norm(X) ** 2 + np.linalg.norm(Theta) ** 2)\n",
    "    return squared_diff + penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "From the cost function,\n",
    "$$\\frac{\\partial J}{\\partial x^{(i)}} = \\sum_{j:y^{(i,j)}\\in \\mathbb{R}} \\left(\\theta^{(j)\\top} x^{(i)}-y^{(i,j)}\\right)\\theta^{(j)} + \\lambda x^{(i)}$$\n",
    "$$\\frac{\\partial J}{\\partial \\theta^{(j)}} = \\sum_{i:y^{(i,j)}\\in \\mathbb{R}} \\left(\\theta^{(j)\\top} x^{(i)}-y^{(i,j)}\\right)x^{(i)} + \\lambda \\theta^{(j)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update(X, Theta, Y, has_rating, reg, alpha):\n",
    "    ni, nu = Y.shape[0], Y.shape[1]\n",
    "    dX = ((X @ Theta.T - Y) * has_rating) @ Theta + reg * X\n",
    "    dTheta =  ((X @ Theta.T - Y) * has_rating).T @ X + reg * Theta   \n",
    "    X -= alpha * dX\n",
    "    Theta -= alpha * dTheta\n",
    "    return X, Theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(Y, has_rating, reg, alpha, n_factor, n_iter):\n",
    "    ni, nu = Y.shape[0], Y.shape[1]\n",
    "    # randomly initialize parameters for symmetry breaking\n",
    "    X = np.random.randn(ni, n_factor)\n",
    "    Theta = np.random.randn(nu, n_factor)\n",
    "    for i in range(n_iter):\n",
    "        if i == 0 or i % 100 == 0:\n",
    "            print(\"Iteration {}, loss = {}\".format(i, compute_cost(X, Theta, Y, has_rating, reg)))\n",
    "        # gradient descent\n",
    "        X, Theta = update(X, Theta, Y, has_rating, reg, alpha)\n",
    "    return X, Theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: Movie Ratings\n",
    "\n",
    "Load movie ratings. Rating ranges from 1 to 10. 0 means movie is not rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1682, 943)\n"
     ]
    }
   ],
   "source": [
    "dat = pd.read_csv(\"movie.csv\", header=None)\n",
    "Y = dat.values\n",
    "has_rating = (Y > 0)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit available ratings without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 121266759.78751318\n",
      "Iteration 100, loss = 29853.05265509899\n",
      "Iteration 200, loss = 9507.080074612975\n",
      "Iteration 300, loss = 4896.117034932882\n",
      "Iteration 400, loss = 3121.577813294124\n",
      "Iteration 500, loss = 2259.130559020625\n",
      "Iteration 600, loss = 1781.5022411073467\n",
      "Iteration 700, loss = 1494.7530935201921\n",
      "Iteration 800, loss = 1312.2943404808077\n",
      "Iteration 900, loss = 1190.5847241946597\n",
      "Iteration 1000, loss = 1105.724812729537\n",
      "Iteration 1100, loss = 1043.7899094980621\n",
      "Iteration 1200, loss = 996.4518840409312\n",
      "Iteration 1300, loss = 958.661426848383\n",
      "Iteration 1400, loss = 927.301442458483\n",
      "Iteration 1500, loss = 900.4014693029166\n",
      "Iteration 1600, loss = 876.681937668676\n",
      "Iteration 1700, loss = 855.2921660614953\n",
      "Iteration 1800, loss = 835.6617893110274\n",
      "Iteration 1900, loss = 817.4141963643846\n",
      "Iteration 2000, loss = 800.3104936752751\n",
      "Iteration 2100, loss = 784.2080712700907\n",
      "Iteration 2200, loss = 769.0277950783516\n",
      "Iteration 2300, loss = 754.7284634233038\n",
      "Iteration 2400, loss = 741.2883482922301\n",
      "Iteration 2500, loss = 728.6932402358318\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(915)\n",
    "X_fitted, Theta_fitted = train(Y, has_rating, 0, 0.0009, 10, 2501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 4, 0, ..., 5, 0, 0],\n",
       "       [3, 0, 0, ..., 0, 0, 5],\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.06435982,  4.40733571,  2.86958667, ...,  4.18291577,\n",
       "         4.44027669,  3.73750388],\n",
       "       [ 3.26669642,  3.53034109,  3.49442406, ...,  2.58727408,\n",
       "         3.82576191,  3.37913655],\n",
       "       [ 2.78499772,  1.51880794,  1.98791109, ...,  2.48822526,\n",
       "         2.93909163,  3.73325698],\n",
       "       ...,\n",
       "       [ 1.35588404,  1.65099614, -0.22001495, ...,  3.3798292 ,\n",
       "         1.09555323,  0.7815146 ],\n",
       "       [ 2.63745887,  3.90036318,  4.05913082, ...,  4.90007577,\n",
       "         5.70655651,  0.99602897],\n",
       "       [ 3.88122052,  4.64577864,  6.34450992, ...,  1.43261582,\n",
       "         2.40620525,  2.62535751]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fitted @ Theta_fitted.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
